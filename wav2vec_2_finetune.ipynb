{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_from_disk\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport os","metadata":{"_uuid":"a8a2db4e-5119-4eba-906f-43c6607c0f3a","_cell_guid":"784fe0ed-6b36-4eb9-8af6-0036c628dc60","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-17T12:56:27.985257Z","iopub.execute_input":"2024-11-17T12:56:27.985644Z","iopub.status.idle":"2024-11-17T12:56:29.675046Z","shell.execute_reply.started":"2024-11-17T12:56:27.985611Z","shell.execute_reply":"2024-11-17T12:56:29.674279Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ds = load_from_disk(\"/kaggle/input/mathbridge-audio-names/mathbridge_speech\")\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:09:34.951711Z","iopub.execute_input":"2024-11-17T13:09:34.952608Z","iopub.status.idle":"2024-11-17T13:09:34.982695Z","shell.execute_reply.started":"2024-11-17T13:09:34.952558Z","shell.execute_reply":"2024-11-17T13:09:34.981762Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['context_before', 'equation', 'context_after', 'spoken_English', 'speech_file'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:09:39.192743Z","iopub.execute_input":"2024-11-17T13:09:39.193403Z","iopub.status.idle":"2024-11-17T13:09:39.199703Z","shell.execute_reply.started":"2024-11-17T13:09:39.193360Z","shell.execute_reply":"2024-11-17T13:09:39.198836Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'context_before': 'are modeled by a stochastic control process with variance',\n 'equation': '$ \\\\sigma^2_t $',\n 'context_after': 'controlled by the agent and with a mean of zero . This models potential effect of actions centered around the null action . To compute various quantities of interest ,',\n 'spoken_English': 'sigma squared sub t.',\n 'speech_file': 'speech/tts_0.mp3'}"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# Load pre-trained model and processor\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\").to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:03:05.490011Z","iopub.execute_input":"2024-11-17T13:03:05.490528Z","iopub.status.idle":"2024-11-17T13:03:06.601793Z","shell.execute_reply.started":"2024-11-17T13:03:05.490488Z","shell.execute_reply":"2024-11-17T13:03:06.600789Z"}},"outputs":[{"name":"stderr","text":"Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# load dummy dataset and read soundfiles\nds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n\n# tokenize\ninput_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values.to(\"cuda\")\n\n# retrieve logits\nlogits = model(input_values).logits\n\n# take argmax and decode\npredicted_ids = torch.argmax(logits, dim=-1)\ntranscription = processor.batch_decode(predicted_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:03:17.531569Z","iopub.execute_input":"2024-11-17T13:03:17.531928Z","iopub.status.idle":"2024-11-17T13:03:19.359875Z","shell.execute_reply.started":"2024-11-17T13:03:17.531895Z","shell.execute_reply":"2024-11-17T13:03:19.359095Z"}},"outputs":[{"name":"stderr","text":"It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:08:28.415471Z","iopub.execute_input":"2024-11-17T13:08:28.415863Z","iopub.status.idle":"2024-11-17T13:08:28.436575Z","shell.execute_reply.started":"2024-11-17T13:08:28.415825Z","shell.execute_reply":"2024-11-17T13:08:28.435576Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'file': '/root/.cache/huggingface/datasets/downloads/extracted/dfbece23564f422bc5794f3090902cd16d52d86767b746125ebc2ff3ea5f89ef/dev_clean/1272/135031/1272-135031-0000.flac',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/dfbece23564f422bc5794f3090902cd16d52d86767b746125ebc2ff3ea5f89ef/dev_clean/1272/135031/1272-135031-0000.flac',\n  'array': array([-0.00018311, -0.00033569, -0.00021362, ..., -0.00323486,\n         -0.00402832, -0.00393677]),\n  'sampling_rate': 16000},\n 'text': 'BECAUSE YOU WERE SLEEPING INSTEAD OF CONQUERING THE LOVELY ROSE PRINCESS HAS BECOME A FIDDLE WITHOUT A BOW WHILE POOR SHAGGY SITS THERE A COOING DOVE',\n 'speaker_id': 1272,\n 'chapter_id': 135031,\n 'id': '1272-135031-0000'}"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Preprocess function\ndef prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    inputs = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\", padding=True)\n    batch[\"input_values\"] = inputs.input_values[0]\n    batch[\"labels\"] = processor.tokenizer.encode(batch[\"latex\"], return_tensors=\"pt\")[0]\n    return batch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Load and preprocess dataset\ndataset = dataset.map(prepare_dataset, remove_columns=[\"audio\", \"latex\"])\n\n# Set training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=4,\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-4,\n    num_train_epochs=5,\n    save_steps=500,\n    logging_dir='./logs'\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=processor.feature_extractor\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}