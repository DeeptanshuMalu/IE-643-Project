{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":9942510,"datasetId":6113097,"databundleVersionId":10203993}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:35:15.224555Z","iopub.execute_input":"2024-11-18T14:35:15.225175Z","iopub.status.idle":"2024-11-18T14:35:28.214356Z","shell.execute_reply.started":"2024-11-18T14:35:15.225128Z","shell.execute_reply":"2024-11-18T14:35:28.213309Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom evaluate import load\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:35:28.216457Z","iopub.execute_input":"2024-11-18T14:35:28.216767Z","iopub.status.idle":"2024-11-18T14:35:47.698249Z","shell.execute_reply.started":"2024-11-18T14:35:28.216732Z","shell.execute_reply":"2024-11-18T14:35:47.697412Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load pre-trained model and processor\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:35:47.699369Z","iopub.execute_input":"2024-11-18T14:35:47.699972Z","iopub.status.idle":"2024-11-18T14:35:56.796998Z","shell.execute_reply.started":"2024-11-18T14:35:47.699939Z","shell.execute_reply":"2024-11-18T14:35:56.796082Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10fb8facafe54123b23a7b3d378548dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143d0af639934d2cb31398d17b3d75af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3280a2729f7e4d4a9cef3287d205086e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f837896133424492aebdd53916c195"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e357cefb4f09416dacc1dd652482eff4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ea038557f645b7902bafb5ab89a4d4"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n\n    # processor: Wav2Vec2BertProcessor\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n\n        labels_batch = self.processor.pad(\n            labels=label_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        del input_features, label_features\n        gc.collect()\n\n        return batch\n\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:35:56.799949Z","iopub.execute_input":"2024-11-18T14:35:56.800345Z","iopub.status.idle":"2024-11-18T14:35:56.810310Z","shell.execute_reply.started":"2024-11-18T14:35:56.800306Z","shell.execute_reply":"2024-11-18T14:35:56.809499Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_set = load_from_disk(\"/kaggle/input/train-test-data-for-w2v2/train_data\")\ntest_set = load_from_disk(\"/kaggle/input/train-test-data-for-w2v2/test_data\")\ntrain_set, test_set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:35:56.811421Z","iopub.execute_input":"2024-11-18T14:35:56.811723Z","iopub.status.idle":"2024-11-18T14:36:00.310353Z","shell.execute_reply.started":"2024-11-18T14:35:56.811689Z","shell.execute_reply":"2024-11-18T14:36:00.309434Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_values', 'input_length', 'labels', 'path'],\n     num_rows: 10000\n }),\n Dataset({\n     features: ['input_values', 'input_length', 'labels', 'path'],\n     num_rows: 1000\n }))"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n  output_dir=\"w2v2 10000\",\n  group_by_length=False,\n  per_device_train_batch_size=4,\n  gradient_accumulation_steps=8,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=10,\n  gradient_checkpointing=True,\n  fp16=True,\n  save_steps=600,\n  eval_steps=300,\n  logging_steps=300,\n  learning_rate=5e-5,\n  warmup_steps=500,\n  save_total_limit=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:36:00.311618Z","iopub.execute_input":"2024-11-18T14:36:00.311928Z","iopub.status.idle":"2024-11-18T14:36:00.432300Z","shell.execute_reply.started":"2024-11-18T14:36:00.311895Z","shell.execute_reply":"2024-11-18T14:36:00.431164Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"bleu = load(\"bleu\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    bleu_val = bleu.compute(predictions=pred_str, references=label_str)\n\n    return {\"bleu\": bleu_val}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:36:00.433491Z","iopub.execute_input":"2024-11-18T14:36:00.433800Z","iopub.status.idle":"2024-11-18T14:36:01.442940Z","shell.execute_reply.started":"2024-11-18T14:36:00.433768Z","shell.execute_reply":"2024-11-18T14:36:01.442093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaa8e7c2b4e445a0942e3854a9ae99dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e5ab9a71ba4956918760b4b4127e72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"435d49b7277749f58e8468d3b7c2e0f2"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_set,\n    eval_dataset=test_set,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:36:01.444089Z","iopub.execute_input":"2024-11-18T14:36:01.444368Z","iopub.status.idle":"2024-11-18T14:36:02.717211Z","shell.execute_reply.started":"2024-11-18T14:36:01.444336Z","shell.execute_reply":"2024-11-18T14:36:02.716426Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"91a0db028dce6f175361702b5140fa9c941bf8ff\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:36:02.718255Z","iopub.execute_input":"2024-11-18T14:36:02.718520Z","iopub.status.idle":"2024-11-18T14:36:03.824201Z","shell.execute_reply.started":"2024-11-18T14:36:02.718490Z","shell.execute_reply":"2024-11-18T14:36:03.823195Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}