{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9942510,"sourceType":"datasetVersion","datasetId":6113097}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:24:49.053548Z","iopub.execute_input":"2024-11-18T14:24:49.053864Z","iopub.status.idle":"2024-11-18T14:25:02.589348Z","shell.execute_reply.started":"2024-11-18T14:24:49.053829Z","shell.execute_reply":"2024-11-18T14:25:02.588439Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom evaluate import load\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:25:09.006967Z","iopub.execute_input":"2024-11-18T14:25:09.007843Z","iopub.status.idle":"2024-11-18T14:25:29.540170Z","shell.execute_reply.started":"2024-11-18T14:25:09.007794Z","shell.execute_reply":"2024-11-18T14:25:29.539316Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load pre-trained model and processor\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:07.410266Z","iopub.execute_input":"2024-11-18T14:30:07.411204Z","iopub.status.idle":"2024-11-18T14:30:09.716581Z","shell.execute_reply.started":"2024-11-18T14:30:07.411155Z","shell.execute_reply":"2024-11-18T14:30:09.715742Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n\n    # processor: Wav2Vec2BertProcessor\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lenghts and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n\n        labels_batch = self.processor.pad(\n            labels=label_features,\n            padding=self.padding,\n            return_tensors=\"pt\",\n        )\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        del input_features, label_features\n        gc.collect()\n\n        return batch\n\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:11.524081Z","iopub.execute_input":"2024-11-18T14:30:11.524484Z","iopub.status.idle":"2024-11-18T14:30:11.536342Z","shell.execute_reply.started":"2024-11-18T14:30:11.524449Z","shell.execute_reply":"2024-11-18T14:30:11.535401Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_set = load_from_disk(\"/kaggle/input/train-test-data-for-w2v2/train_data\")\ntest_set = load_from_disk(\"/kaggle/input/train-test-data-for-w2v2/test_data\")\ntrain_set, test_set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:12.054690Z","iopub.execute_input":"2024-11-18T14:30:12.055055Z","iopub.status.idle":"2024-11-18T14:30:15.271691Z","shell.execute_reply.started":"2024-11-18T14:30:12.055021Z","shell.execute_reply":"2024-11-18T14:30:15.270662Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_values', 'input_length', 'labels', 'path'],\n     num_rows: 10000\n }),\n Dataset({\n     features: ['input_values', 'input_length', 'labels', 'path'],\n     num_rows: 1000\n }))"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n  output_dir=\"w2v2 10000\",\n  group_by_length=False,\n  per_device_train_batch_size=4,\n  gradient_accumulation_steps=8,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=10,\n  gradient_checkpointing=True,\n  fp16=True,\n  save_steps=600,\n  eval_steps=300,\n  logging_steps=300,\n  learning_rate=5e-5,\n  warmup_steps=500,\n  save_total_limit=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:15.273654Z","iopub.execute_input":"2024-11-18T14:30:15.274378Z","iopub.status.idle":"2024-11-18T14:30:15.311430Z","shell.execute_reply.started":"2024-11-18T14:30:15.274331Z","shell.execute_reply":"2024-11-18T14:30:15.310361Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"bleu = load(\"bleu\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    bleu_val = bleu.compute(predictions=pred_str, references=label_str)\n\n    return {\"bleu\": bleu_val}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:15.312789Z","iopub.execute_input":"2024-11-18T14:30:15.313470Z","iopub.status.idle":"2024-11-18T14:30:17.822289Z","shell.execute_reply.started":"2024-11-18T14:30:15.313423Z","shell.execute_reply":"2024-11-18T14:30:17.821321Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_set,\n    eval_dataset=test_set,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T14:30:17.824171Z","iopub.execute_input":"2024-11-18T14:30:17.824478Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"91a0db028dce6f175361702b5140fa9c941bf8ff\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}